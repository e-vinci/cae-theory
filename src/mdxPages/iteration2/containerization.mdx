---
title: Conteneurisation
description: Conteneurisation
date: 05/02/2025
---

<InternalPageMenu>
  <PathViewer>
    <PathViewerItem to="/"> CAE </PathViewerItem>
    <PathViewerItem to="/iteration2"> Itération 2 </PathViewerItem>
    <PathViewerItem selected> Conteneurisations </PathViewerItem>
  </PathViewer>
  <InternalPageMenuItem> Qu'est ce que la conteneurisation ? </InternalPageMenuItem>
  <InternalPageMenuItem> Comment créer un container Docker et l'exécuter ? </InternalPageMenuItem>
  <InternalPageMenuItem> Comment créer un container Docker pour la production ? </InternalPageMenuItem>
  <InternalPageMenuItem> Comment optimiser une image Docker pour la production ? </InternalPageMenuItem>
  <InternalPageMenuItem> Comment créer une application multi-conteneurs ? </InternalPageMenuItem>
  <InternalPageMenuItem> Comment connecter tous les services dans une application multi-conteneurs ? </InternalPageMenuItem>
  <InternalPageMenuItem> Comment réaliser les tests e2e dans l'environnement de production local ? </InternalPageMenuItem>
    <InternalPageMenuItem> Comment ignorer les fichiers qui ne peuvent pas se retrouver dans l'image ? </InternalPageMenuItem>
    <InternalPageMenuItem> Comment exécuter docker compose dans notre pipeline ? </InternalPageMenuItem>
  <InternalPageMenuItem> Comment gérer des règles pour notre pipelines ? </InternalPageMenuItem>
</InternalPageMenu>

# <InternalPageTitle> Qu'est ce que la conteneurisation ? </InternalPageTitle>

## Définition

La conteneurisation encapsule une application et ses dépendances dans un conteneur léger et portable. Les conteneurs partagent le noyau du système d'exploitation hôte, mais sont isolés les uns des autres.

Un conteneur est une unité logicielle qui regroupe le code et toutes ses dépendances, de sorte que l'application puisse s'exécuter rapidement et de manière fiable d'un environnement informatique à un autre.

Attention à ne pas confondre la conteneurisation avec la virtualisation. La virtualisation consiste à exécuter plusieurs systèmes d'exploitation sur un seul serveur physique, tandis que la conteneurisation consiste à exécuter plusieurs conteneurs sur un seul système d'exploitation.

## Pourquoi la conteneurisation ?

Dans la partie sur la gestion des environnements, nous avons vu que les environnements de développement, de tests et de production peuvent être différents.

La conteneurisation permet de s'assurer que l'application fonctionne de la même manière dans tous les environnements, en encapsulant l'application et toutes ses dépendances dans un conteneur.

## Comment fonctionne la conteneurisation ?

La conteneurisation repose sur une technologie appelée **Docker**. Docker est un outil qui permet de créer, de déployer et de gérer des conteneurs.

Un **conteneur** Docker (**container** en anglais) est une instance d'une image Docker. 

Une **image** Docker est un modèle de conteneur qui contient le code de l'application, ses dépendances et les paramètres d'exécution.

Voici à quoi nous souhaitons que ressemble notre environnement de **tests**, qui doit être proche du futur environnement de production :

<PlantUML src="/diagrams/conteneurisation.puml" alt="test-environment"  />

Voici quelques explications sur les différents éléments de l'environnement de tests :

- **Docker Host** : Représente le serveur hôte où Docker est installé. Nous pourrions décider d'utiliser un serveur local ou un serveur au sein de GitLab CI/CD.
- **Frontend** : Conteneur pour l'application frontend (par exemple, React).
- **API** : Conteneur pour l'API (par exemple, Spring Boot).
- **Database** (DB) : Conteneur pour la base de données (par exemple, PostgreSQL).
- **E2E Tests** : Conteneur pour les tests end-to-end (par exemple, Playwright).
- **Développeur / Développeuse** : Personne qui interagit avec les différents conteneurs pour développer et tester l'application.

Afin de faciliter la vie pour les développeurs, nous allons automatiser la création des conteneurs à l'aide de **Docker Compose**.

## Docker Compose

**Docker Compose** est un outil qui permet de définir et de gérer des applications multi-conteneurs. 

Il permet de gérer un réseau de conteneurs Docker, de spécifier les dépendances entre les conteneurs, de configurer les paramètres d'exécution, etc.

Voici un schéma de l'architecture de notre application multi-conteneurs :

<PlantUML src="/diagrams/docker-compose.puml" alt="docker-compose"  />

Pour les développeurs, Docker Compose permet de démarrer et d'arrêter l'application en une seule commande, de configurer les paramètres d'exécution, de gérer les dépendances entre les conteneurs, etc.

# <InternalPageTitle> Comment créer un container Docker et l'exécuter ? </InternalPageTitle>

## Outils nécessaires

Vous aurez besoin d'installer **Docker Desktop** pour créer et gérer des conteneurs Docker sur votre ordinateur.

Suivez bien les instructions d'installation pour votre système d'exploitation : https://docs.docker.com/desktop/

**Docker Desktop** intègre notamment **Docker Compose** afin de pouvoir gérer des applications multi-conteneurs.

## Introduction 

Pour créer un **conteneur** Docker, vous devez d'abord créer une **image** Docker. Vous pouvez créer une **image** Docker à partir d'un fichier de configuration appelé **`Dockerfile`**.

Un **`Dockerfile`** est un fichier texte qui contient les instructions pour créer une image Docker. Il spécifie les dépendances de l'application, les commandes d'installation, les paramètres d'exécution, etc.

Une fois que vous avez créé une **image** Docker, vous pouvez notamment créer un **conteneur** Docker à partir de cette **image** en utilisant la commande **`docker run`**.

Pour ce tutoriel, nous allons travailler directement dans notre projet GitLab. Pensez donc à créer une nouvelle branche pour accueillir le code de ce tutoriel.

Si nécessaire, vous pouvez trouver le code de démarrage de ce tutoriel ici : [e2e-tests](https://github.com/e-vinci/cae-theory-demos/tree/main/e2e-tests).

## Créer une image pour l'environnement de développement

Nous allons commencer par créer une **image** Docker pour un environnement de développement.

Nous allons créer une image pour le frontend de notre projet.

Créez un fichier **`Dockerfile`** à la racine de votre projet **`/frontend`** avec le contenu suivant :

```Dockerfile
FROM node:20

WORKDIR /usr/src/app

COPY . .

RUN npm install

CMD ["npm", "run", "dev", "--", "--host"]
```

Voici les explications des différentes instructions du **`Dockerfile`** :
- **`FROM node:20`** : 
  - Utilise l'image de base **`node:20`** qui contient Node.js. 
  - Cette image est téléchargée depuis le Docker Hub. 
  - La version **`20`** de Node.js est utilisée. Notons que l'image `node` offre aussi **`npm`**.
  - Vous pouvez trouver d'autres images de base sur le Docker Hub : https://hub.docker.com/
- **`WORKDIR /usr/src/app`** : 
  - Définit le répertoire de travail pour les commandes suivantes.
  - Crée le répertoire **`/usr/src/app`** dans l'image.
  - Pourquoi **`/usr/src/app`** ? C'est une convention pour les applications Node.js. On aurait pu mettre ce que l'on souhaite, comme **`/app`** par exemple.
- **`COPY . .`** :
  - Copie tous les fichiers du répertoire courant (votre projet) dans le répertoire de travail de l'image.
- **`RUN npm install`** :
  - **`RUN`** exécute une commande dans l'image.
  - Installe les dépendances du projet avec **`npm`**.
- **`CMD ["npm", "run", "dev", "--", "--host"]`** :
  - **`CMD`** définit la commande par défaut à exécuter lorsque le conteneur est démarré.
  - Exécute la commande **`npm run dev`** pour démarrer l'application en mode développement.
  - L'option **`--host`** permet de spécifier l'hôte sur lequel l'application doit écouter. Comme aucune adresse IP n'est spécifiée, l'application écoute sur toutes les interfaces réseau.

Pour créer l'image Docker, nous pourrions exécuter la commande suivante à la racine de notre projet **`/frontend`** :

```bash
docker build -t frontend .
```

Cependant, nous allons automatiser la création et l'exécution des conteneurs à l'aide de **Docker Compose**. Plutôt que de vous apprendre plein de commandes Docker, nous allons voir comment se simplifier la vie avec **Docker Compose**.

## Créer un fichier `docker-compose.yml`

Créez un fichier **`docker-compose.yml`** à la racine de votre projet avec le contenu suivant :

```yaml
services:
  frontend:
    image: frontend-dev
    build: ./frontend
    ports:
      - 5173:5173
    volumes:
      - ./frontend:/usr/src/app
      - /usr/src/app/node_modules
```

Voici les explications des différentes instructions du **`docker-compose.yml`** :
- **`services`** : 
  - Définit les services (conteneurs) de l'application.
- **`frontend`** : 
  - Nom du service.
- **`image: frontend-dev`** : 
  - Nom de l'image à utiliser pour le service.
  - Si l'image n'existe pas, elle sera créée à partir du **`Dockerfile`**.
- **`build: ./frontend`** : 
  - Chemin vers le répertoire contenant le **`Dockerfile`**.
- **`ports: - 5173:5173`** :
  - Redirige le port **`5173`** du conteneur vers le port **`5173`** de l'hôte.
  - **L'hôte** est votre ordinateur si vous êtes dans votre environnement de développement.
  - Cela permet d'accéder à l'application depuis l'hôte.
- **`volumes: - ./frontend:/usr/src/app`** :
  - Monte le répertoire du projet sur l'hôte dans le répertoire de travail du conteneur.
  - Cela permet de synchroniser les fichiers entre l'hôte et le conteneur.
  - Si à partir de son éditeur de code, les développeurs modifient un fichier, les modifications seront automatiquement prises en compte dans le conteneur. Docker Compose se charge de synchroniser les fichiers et de redémarrer le conteneur si nécessaire.
- **`volumes: - /usr/src/app/node_modules`** :
  - Montage d'un volume pour le répertoire **`node_modules`**.
  - Cela permet de conserver les dépendances installées par **`npm`** entre les redémarrages du conteneur. 
  - les volumes sont stockés sur l'hôte Docker (votre machine) et non à l'intérieur du conteneur. Ils permettent de persister des données même si le conteneur est supprimé ou recréé.
  - **Utilisation comme cache** : Lorsqu'un volume est utilisé pour stocker des dépendances (par exemple, des modules Node.js), Docker Compose permet de réutiliser ces dépendances entre les exécutions de conteneurs, ce qui peut accélérer les temps de construction et de démarrage.

Veuillez démarrer :
- Docker Desktop ; il suffit normalement de cliquer sur l'icône de Docker Desktop pour le démarrer.
- Votre base de données PostgreSQL en tapant la commande suivante à la racine de votre projet **`/api` : `docker compose up --build`**.
- Votre API Spring Boot se trouvant dans le répertoire **`/api`** à l'aide d'IntelliJ ou de Maven. 
- VS Code pour travailler dans le répertoire **`/frontend`**.

Veuillez démarrer votre frontend à l'aide de **Docker Compose** en exécutant la commande suivante à la racine de votre projet GitLab (là où se trouve le nouveau fichier **`docker-compose.yml`**) :

```bash
docker compose up --build
```

Quelques explications sur la commande **`docker compose up --build`** :
- **`docker compose up`** : 
  - Démarre l'application multi-conteneurs.
  - Crée et démarre les conteneurs définis dans le fichier **`docker-compose.yml`**.
- **`--build`** :
  - Si vous avez modifié le **`Dockerfile`** ou le **`docker-compose.yml`**, vous devez reconstruire les images. Cela permet de s'assurer que les modifications sont prises en compte.
- Cherche un fichier **`docker-compose.yml`** dans le répertoire courant pour démarrer les conteneurs.
- Possible de spécifier un fichier **`docker-compose.yml`** avec l'option **`-f`**. Par exemple :  
**`docker compose -f docker-compose.prod.yml up --build`**.


Une fois le frontend lancé, vous devriez voir que celui-ci s'affiche presque bien.  
Le souci est que le frontend n'arrive pas à communiquer avec l'API.  
Mais pourquoi ?  
Lorsque vous exécutez une application frontend dans un conteneur Docker et que l'API tourne à l'extérieur de Docker (sur l'hôte), il y a une séparation réseau entre le conteneur et l'hôte. Voici pourquoi `localhost` ne fonctionne pas dans ce cas :

- Isolation Réseau : Chaque conteneur Docker a son propre espace réseau isolé. `localhost` dans un conteneur fait référence à ce conteneur lui-même, pas à l'hôte ou à d'autres conteneurs.
- Adresse IP Différente : L'hôte et les conteneurs ont des adresses IP différentes. `localhost` (équivalent de `127.0.0.1`) dans le conteneur ne peut pas atteindre `localhost` sur l'hôte.

Pour résoudre ce problème, nous allons prochainement dockeriser l'API et l'ajouter au **`docker-compose.yml`**.  
De cette façon, le frontend pourra communiquer avec l'API via le nom du service défini dans le **`docker-compose.yml`**.

Mais avant de continuer, observons ce qui se passe lorsque l'on modifie un fichier dans le frontend.

## Visualiser la synchronisation des fichiers

Veuillez mettre à jour le fichier **`/frontend/src/components/pages/HomePage.tsx`** de votre frontend pour afficher un titre différent :

```tsx {2}
<Typography variant="h2" component="h1" gutterBottom>
        My Amazing HomePage
</Typography>
```

Ici, nous avons ajouté le mot **`Amazing`** pour rendre le titre plus attrayant. Comme nous avons monté le répertoire du projet sur l'hôte dans le conteneur, les modifications apportées au fichier **`HomePage.tsx`** sont automatiquement synchronisées avec le conteneur. Et **Vite** (le builder de notre frontend) s'occupe d'automatiquement recharger la page pour afficher les modifications !

## Arrêt de l'application

Pour arrêter l'application lancée par Docker Compose sans supprimer les conteneurs, vous pouvez : 
- soit appuyer sur **`CTRL C`** ;
- soit sur Docker Desktop, sélectionnez l'onglet **`Containers`**, cliquer sur le bouton **`Stop`** associé à votre container.

Dans ce cas là, les conteneurs, les réseaux, les volumes, etc. sont conservés.
Vous pouvez redémarrer l'application en exécutant la commande **`docker compose up`**.

Pour arrêter l'application et supprimer les conteneurs, les réseaux, les volumes anonymes, etc., vous pouvez exécutez la commande suivante :

```bash
docker compose down
```

## Conclusion sur la création et l'exécution d'un conteneur Docker

Dans ce tutoriel, nous avons vu comment créer une image Docker pour un environnement de développement, comment créer un conteneur Docker à partir de cette image, et comment démarrer une image.

Néanmoins, tout n'est pas parfait. En effet :
- le frontend ne peut pas communiquer avec l'API car l'API n'est pas dockerisée.
- nous avons créé une image pour l'environnement de développement, mais ça n'est pas vraiment utile pour le moment. En effet, nous aurions pu simplement démarrer l'application en local sans Docker.
- la taille de l'image du frontend est assez grande : 1.48GB ! 

Nous allons dans un premier temps voir comment créer une image pour un environnement de tests très proche d'un environnement de production.  

Puis nous verrons comment dockeriser l'API et l'ajouter au **`docker-compose.yml`** pour que le frontend puisse communiquer avec l'API.  
Nous verrons aussi comment configurer les conteneurs pour qu'ils puissent communiquer entre eux.


# <InternalPageTitle> Comment créer un container Docker pour la production ? </InternalPageTitle>

## Introduction

Lorsque nous souhaitons réaliser des tests ou déployer notre application, nous avons besoin de créer une image Docker pour un environnement de tests ou de production.

Dans la phase de tests, nous voulons tester l'application dans un environnement similaire à celui de production. Cela nous permet de détecter les problèmes potentiels avant de déployer l'application en production.

Ainsi, nous devons apprendre à créer une image Docker qui est optimisée pour la production.

## Créer une image pour l'environnement de production

Pour créer une image Docker pour l'environnement de production, nous devons optimiser l'image pour la performance.

Pour ce tutoriel, nous allons donc mettre à jour l'image Docker pour le frontend de notre projet.

Veuillez mettre à jour le fichier **`Dockerfile`** à la racine de votre projet `/frontend` avec le contenu suivant :

```Dockerfile
FROM node:20-alpine

WORKDIR /app

COPY package*.json ./

RUN npm ci

COPY . .

RUN npm run build

RUN npm install -g serve

EXPOSE 5172

CMD ["serve", "-s", "dist", "-l", "5172"]
```

Voici les explications des différentes instructions du **`Dockerfile`** :
- **`FROM node:20-alpine`** : 
  - Utilise l'image de base **`node:20-alpine`** qui contient Node.js.
  - **`alpine`** est une version allégée de l'image de base.
  - Les images **`alpine`** sont plus petites que les images de base standard, ce qui les rend idéales pour les environnements de production.
- **`WORKDIR /app`** : 
  - Définit le répertoire de travail pour les commandes suivantes.
- **`COPY package*.json ./`** :
  - Copie les fichiers **`package.json`** et **`package-lock.json`** dans le répertoire de travail.
- **`RUN npm ci`** : 
  - Installe les dépendances du projet sur base du fichier **`package-lock.json`**.
  - Cela permet de garantir que les dépendances installées sont les mêmes dans l'environnement de tests et de production que celles utilisées lors du développement. Pour ce cas, dans le **`Dockerfile`**, on copie d'abord les fichiers **`package*.json`** et on installe les dépendances avec **`RUN npm ci`**. 
  - Cela impose que l'environnement de développement soit le même que l'environnement de production. En cas de souci, il faudra donc vérifier que les versions de Node.js et de npm sont les mêmes dans les différents environnements.
  - NB : si l'on souhaitait une flexibilité entre l'environnement de développement et les environnements de tests et de production concernant l'installation des dépendances, on installerait les dépendances avec **`RUN npm install`**.
- **`COPY . .`** :
  - Copie tous les fichiers du répertoire courant (votre projet) dans le répertoire de travail de l'image.
- **`RUN npm run build`** :
  - Construit l'application en mode production. Il n'y aura plus de serveur de développement pour une application en production. De plus, on utilisera pas **Vite** pour servir l'application, mais un serveur de fichiers statiques.
  - Tous les fichiers de l'application sont générés dans le répertoire **`dist`** du frontend. Les fichiers TypeScript sont compilés en fichiers JavaScript, les fichiers CSS sont minifiés, etc.
- **`RUN npm install -g serve`** :
  - Installe le serveur **`serve`** pour servir l'application. C'est un serveur de fichiers statiques.
- **`EXPOSE 5172`** :
  - Expose le port **`5172`** du conteneur.
- **`CMD ["serve", "-s", "dist", "-l", "5172"]`** :
  - Démarre le serveur **`serve`** pour servir l'application en mode production.
  - **`-s dist`** : Spécifie le répertoire à servir.
  - **`-l 5172`** : Spécifie le port sur lequel le serveur doit écouter.  

Pourquoi avoir séparé la copie des fichiers **`package.json`** et **`package-lock.json`** de l'installation des dépendances ?  
Si le fichier **`package.json`** n'a pas changé, Docker peut utiliser le cache pour éviter de réinstaller les dépendances à chaque modification du code. Nous allons voir plus tard comment Docker utilise le cache pour accélérer la construction des images.

Pour créer et exécuter l'image Docker, nous allons utiliser **Docker Compose**.

Veuillez mettre à jour le fichier **`docker-compose.yml`** à la racine de votre projet avec le contenu suivant :

```yaml
services:
  frontend:
    container_name: frontend-prod
    image: frontend-prod
    build: ./frontend
    ports:
      - 5172:5172
```

Maintenant que nous avons mis à jour le **`Dockerfile`** et le **`docker-compose.yml`**, nous pouvons créer et exécuter l'image Docker pour l'environnement de production.

Veuillez exécuter la commande suivante à la racine de votre projet GitLab :

```bash
docker compose up --build
```

Quelle est la taille actuelle de l'image Docker pour l'environnement de production ? 726.99 MB. C'est déjà mieux que l'image pour l'environnement de développement (1.48 GB), mais nous pouvons encore l'optimiser.

# <InternalPageTitle> Comment optimiser une image Docker pour la production ? </InternalPageTitle>

## Introduction

Lorsque nous créons une image Docker pour l'environnement de production, nous devons optimiser l'image pour la performance. Nous allons voir quelques bonnes pratiques pour optimiser une image Docker pour la production :
- **Utiliser une image de base légère** : Utilisez une image de base légère comme **`alpine`** pour réduire la taille de l'image.
- **Copier les fichiers de manière sélective** : Copiez les fichiers nécessaires pour l'application et évitez de copier les fichiers inutiles.
- **Utiliser des couches de manière efficace** : Utilisez des couches pour réduire le temps de construction de l'image.
- **Nettoyer les dépendances inutiles** : Supprimez les dépendances inutiles pour réduire la taille de l'image.
- **Utiliser des volumes pour les données persistantes** : Utilisez des volumes pour stocker les données persistantes en dehors de l'image.
- **Utiliser des fichiers `.dockerignore`** : Utilisez des fichiers **`.dockerignore`** pour exclure les fichiers inutiles de l'image. On peut par exemple exclure les dépendances car elles sont installées à chaque construction de l'image.
- **Utiliser des variables d'environnement** : Utilisez des variables d'environnement pour configurer l'application. 
- **Utiliser des multi-stages builds** : Utilisez des multi-stages builds pour réduire la taille de l'image finale.

Nous allons détailler certaines de ces bonnes pratiques pour optimiser l'image Docker pour l'environnement de production.

## Utilisation d'une image de base légère

Pour optimiser l'image Docker pour l'environnement de production, nous vous recommandons d'utiliser une image de base légère comme **`alpine`**. Les images **`alpine`** sont plus petites que les images de base standard, ce qui les rend idéales pour les environnements de production.

Pour trouver les variantes d'une image Docker, vous pouvez consulter le Docker Hub. Par exemple, pour l'image **`node`**, vous pouvez trouver les variantes disponibles sur le Docker Hub : https://hub.docker.com/_/node

Vous pouvez cliquer sur l'onglet **`Tags`** pour voir les différentes variantes disponibles.
Il suffit de choisir la variante qui convient le mieux à votre application.

Si vous souhaitiez une variante de l'image **`node`** qui soit moins légère que **`alpine`** mais compatible avec Debian, vous pourriez choisir **`slim`**.

Dans le **`Dockerfile`** du frontend, on mettrait alors (ne pas le faire pour ce tutoriel):

```Dockerfile
FROM node:20-slim
```

Nous vous recommandons d'aller voir la taille de cette image sur le Docker Hub par rapport à l'image **`alpine`**.

## Utilisation des couches de Docker

### Introduction 

Docker utilise un système de couches pour construire et gérer les images. Chaque instruction dans un Dockerfile crée une nouvelle couche dans l'image Docker. Les couches sont empilées les unes sur les autres pour former l'image finale. Voici comment cela fonctionne :
- **Base Layer** : La première couche est généralement une image de base (par exemple, **`node:20-alpine`**).
- **Intermediate Layers** : Chaque instruction suivante dans le Dockerfile crée une nouvelle couche intermédiaire.
- **Final Layer** : La dernière couche est l'image finale qui inclut toutes les modifications apportées par les instructions précédentes.

### Cache des Couches

Docker utilise un système de cache pour accélérer la construction des images. Si une couche n'a pas changé depuis la dernière construction, Docker peut utiliser le cache pour éviter de reconstruire cette couche. Cela permet de réduire le temps de construction de l'image.

Que se passe-t-il si une couche change ? Toutes les couches suivantes doivent être reconstruites. C'est pourquoi il est important de structurer le Dockerfile de manière à ce que les parties qui changent le plus souvent soient les dernières instructions.

## Utilisation de `.dockerignore`

Le fichier **`.dockerignore`** permet d'exclure les fichiers inutiles, présents sur l'hôte, de l'image Docker. Cela permet principalement :
- de réduire la taille de l'image en excluant les fichiers inutiles.
- d'accélérer la construction de l'image en évitant de copier des fichiers inutiles.
- d'assurer que les dépendances installée correspondent à celles spécifiées dans le **`package-lock.json`** (si vous utilisez **`npm ci`**) ou dans le **`package.json`** (si vous utilisez **`npm install`**). En effet, on ne veut pas que des dépendances installées dans l'environnement de développement soient copiées dans l'image de production. 

Veuillez créer un fichier **`.dockerignore`** à la racine de votre projet `/frontend` avec le contenu suivant :

```plaintext
node_modules
dist
.git
.gitignore
Dockerfile
docker-compose.yml
README.md
```

Dans ce fichier, nous excluons principalement tout ce qui se trouve dans **`node_modules`** et **`dist`** de l'image Docker. Ces fichiers ne sont pas nécessaires pour l'application frontend car les dépendances sont installées à chaque construction de l'image, et le build de l'application est produit à chaque exécution du conteneur du frontend.

Avec cet ajout, la taille de l'image Docker pour l'environnement de production est maintenant de 495,35 MB. C'est une taille un peu plus raisonnable pour une application frontend, mais nous pouvons encore faire mieux.

## Utilisation de multi-stages builds

Les **multi-stages builds** permettent de réduire la taille de l'image finale en utilisant plusieurs étapes de construction. Chaque étape de construction crée une image intermédiaire qui est utilisée pour construire l'étape suivante. Cela permet de réduire la taille de l'image finale en ne conservant que les fichiers nécessaires pour l'application.

L'image finale n'est pas la somme des images intermédiaires, mais seulement la dernière image intermédiaire.

Voici l'image du frontend optimisée pour la production en utilisant deux étapes de construction ; veuillez mettre à jour le fichier **`Dockerfile`** à la racine de votre projet `/frontend` avec le contenu suivant :

```Dockerfile
FROM node:20-alpine AS build

WORKDIR /app

COPY package*.json ./

RUN npm ci

COPY . .

RUN npm run build

FROM node:20-alpine AS prod

WORKDIR /app

COPY --from=build /app/dist ./dist

RUN npm install -g serve

EXPOSE 517

CMD ["serve", "-s", "dist", "-l", "5173"]
```

Nous avons un frontend qui est construit dans une première étape de construction (**`build`**), puis copié dans une deuxième étape de construction (**`prod`**). Cela permet de réduire la taille de l'image finale en ne conservant que les fichiers nécessaires pour l'application. 

La taille de l'image Docker pour l'environnement de production est maintenant de 155,27 MB.

## Nouvelle optimisation de l'image Docker de base

Pour optimiser davantage l'image Docker du frontend, nous pouvons utiliser une image de base plus légère pour la dernière étape de construction de notre image (pour le stage nommé **`prod`**) . Nous utiliserons une image de base offrant juste un serveur de fichiers statiques pour servir l'application.

Veuillez mettre à jour le fichier **`Dockerfile`** à la racine de votre projet **`/frontend`** avec le contenu suivant :

```Dockerfile
FROM node:20-alpine AS build

WORKDIR /app

COPY package*.json ./

RUN npm ci

COPY . .

RUN npm run build

FROM nginx:alpine AS prod

WORKDIR /usr/share/nginx/html

COPY --from=build /app/dist .

EXPOSE 80
```

Voici les explications des différentes nouvelles instructions du **`Dockerfile`** :
- **`FROM node:20-alpine AS build`** : 
  - Utilise l'image de base **`node:20-alpine`** pour la première étape de construction.
  - **`AS build`** : Nomme l'étape de construction (= un **stage**) **`build`**.
- **`FROM nginx:alpine AS prod`** : 
  - Utilise l'image de base **`nginx:alpine`** pour la deuxième étape de construction.
  - **nginx** est un serveur web léger qui peut servir des fichiers statiques. Nous verrons plus tard que **nginx** est souvent utilisé pour servir des applications web en production, pour offrir des services de proxy, de cache, etc.
  - **`AS prod`** : Nomme l'étape de construction **`prod`**.
- **`WORKDIR /usr/share/nginx/html`** : 
  - Définit le répertoire de travail pour les commandes suivantes.
  - **nginx** sert les fichiers statiques à partir de ce répertoire.
- **`COPY --from=build /app/dist .`** :
  - Copie les fichiers de l'étape de construction **`build`** dans le répertoire de travail de l'étape de construction **`prod`**.
  - Cela copie les fichiers de l'application frontend dans le répertoire de **nginx** pour les servir.  
- **`EXPOSE 80`** :
  - Expose le port **`80`** du conteneur. **nginx** écoute sur le port **`80`** par défaut. Le seul moyen de configurer ce port est de modifier la configuration de **nginx**, mais nous n'en avons pas besoin pour le moment.

Pour créer et exécuter l'image Docker, nous allons utiliser **Docker Compose**.

Veuillez mettre à jour le fichier **`docker-compose.yml`** à la racine de votre projet avec le contenu suivant :

```yaml {6-7}
services:
  frontend:
    container_name: frontend-prod
    image: frontend-prod
    build: ./frontend
    ports:
      - 80:80
```

Avec **`80:80`**, nous redirigeons le port **`80`** du conteneur vers le port **`80`** de l'hôte. **nginx** écoute sur le port **`80`** par défaut.

Maintenant que nous avons mis à jour le **`Dockerfile`** et le **`docker-compose.yml`**, nous pouvons créer et exécuter l'image Docker pour l'environnement de tests et de production.

Veuillez exécuter la commande suivante à la racine de votre projet GitLab :

```bash
docker compose up --build
```

La taille de l'image Docker pour l'environnement de production est maintenant de 59,58 MB !  
C'est une taille beaucoup plus raisonnable pour une application frontend.

Veuillez ouvrir un navigateur et accéder à l'adresse **`http://localhost`** pour voir l'application frontend tel qu'elle serait en production. Vous devriez voir l'application frontend servie par **nginx**. Néanmoins, vous ne verrez pas tout car l'application frontend n'arrive pas à communiquer avec l'API. Nous allons prochainement voir comment dockeriser l'API et l'ajouter au **`docker-compose.yml`** pour que le frontend puisse communiquer avec l'API.

## Conclusion sur l'optimisation d'une image Docker pour la production

Dans ce tutoriel, nous avons vu plusieurs moyens d'optimiser une image Docker pour la production. 

Au final, obtenir une image légère permet :
- **d'augmenter la sécurité** : moins de dépendances signifie moins de failles de sécurité potentielles.
- **d'améliorer les performances** : une image légère se déploie plus rapidement et consomme moins de ressources.
- **de réduire les coûts** : une image légère nécessite moins de stockage et de bande passante.

Il existe encore d'autre façons d'optimiser une image Docker pour la production que nous ne verrons pas dans ce cours. N'hésitez pas à creuser le sujet si cela vous intéresse.


# <InternalPageTitle> Comment créer une application multi-conteneurs ? </InternalPageTitle>

## Introduction

Dans ce tutoriel, nous allons voir comment dockeriser l'API et l'ajouter au **`docker-compose.yml`** pour que le frontend puisse communiquer avec l'API. Nous verrons aussi comment configurer les conteneurs pour qu'ils puissent communiquer entre eux.

## Dockeriser l'API

Pour dockeriser l'API, nous allons directement créer une image Docker de l'application Spring pour la production. Nous allons utiliser un **multi-stages build** pour optimiser l'image Docker :
- La première étape de construction (**`build`**) installera les dépendances et construira l'application à l'aide d'une image **Maven**. Le but est d'obtenir un fichier **`.jar`**.
- La deuxième étape de construction (**`prod`**) copiera le fichier **`.jar`** dans une image **Java** pour l'exécuter.

Veuillez ajouter un fichier **`Dockerfile`** à la racine de votre projet `/api` avec le contenu suivant :

```Dockerfile
FROM maven:3.9.9-amazoncorretto-21 AS build

WORKDIR /app

COPY pom.xml .
COPY src ./src

RUN mvn clean package -Dno-build-failure

FROM amazoncorretto:21

WORKDIR /app

COPY --from=build /app/target/*.jar app.jar

EXPOSE 3000

CMD ["java", "-jar", "app.jar"]
```

Voici quelques explications pour les parties importantes du **`Dockerfile`** :
- **Application Maven** : 
  - L'API Spring Boot utilise Maven comme outil de build. Nous utilisons donc une image **Maven** pour construire l'application.
  - Une application Maven est composée de plusieurs fichiers, dont un fichier **`pom.xml`** qui contient les dépendances et les configurations du projet et un répertoire **`src`** qui contient le code source de l'application.
  - Nous ne souhaitons pas exécuter les tests lors de la construction de l'image, c'est pourquoi nous utilisons l'option **`-Dno-build-failure`**. Cela active le profil **`no-build-failure`** qui est défini dans le **`pom.xml`** et qui permet de construire l'application même si les tests échouent. Nous avons vu cela dans le tutoriel sur les tests unitaires de l'API.
- **Application Java** :
  - L'API Spring Boot est une application Java qui s'exécute sur une machine virtuelle Java (JVM). Nous utilisons donc une image **Java** pour exécuter l'application.
  - Nous copions le fichier **`.jar`** de l'étape de construction **`build`** dans l'image **Java** pour l'exécuter.

Pour créer et exécuter l'image Docker, nous allons utiliser **Docker Compose**.

Veuillez mettre à jour le fichier **`docker-compose.yml`** à la racine de votre projet avec le contenu suivant :

```yaml {9-10,12-20,22-30} showLineNumbers
services:
  frontend:
    container_name: frontend-prod
    image: frontend-prod
    build: 
      context: ./frontend
    ports:
      - 80:80
    depends_on:
      - api

  api:
    container_name: api-prod
    image: api-prod
    build: ./api
    ports:
      - 3000:3000
    depends_on:
      - db
    entrypoint: ["java", "-jar", "app.jar", "--spring.profiles.active=test"]

  db:
    image: postgres:latest
    container_name: db-test
    environment:
      POSTGRES_DB: cae_db
      POSTGRES_USER: cae_user
      POSTGRES_PASSWORD: cae
    ports:
      - "5432:5432"
```

Nous avons ajouté un service **`api`** pour l'API Spring Boot.

Comme la base de données est utilisé par le service **`api`**, nous avons ajouté un service **`db`**. Comme le service **`db`** est au sein du même `docker-compose` que le service **`api`**, le service **`api`** pourra communiquer avec le service **`db`** via le nom du service **`db`**.

Nous avons également ajouté une instruction **`depends_on`** pour le service **`api`** et le service **`db`** :
- **`depends_on`** : 
  - Définit l'ordre de démarrage des services.
  - Ici, le service **`api`** dépend du service **`db`**. Cela signifie que le service **`db`** sera démarré avant le service **`api**.
  - Ici, le service **`frontend`** dépend du service **`api`**. Cela signifie que le service **`api`** sera démarré avant le service **`frontend**.
  - Attention, **`depends_on`** ne garantit pas que le service dépendant est prêt avant de démarrer le service dépendant. Pour attendre que le service dépendant soit prêt, il faut utiliser des outils qu'il est possible d'ajouter à l'image Docker, comme **`wait-for-it.sh`** ou **`dockerize`**. Nous ne verrons probablement pas cela dans ce cours, nous utiliserons une autre méthode extra simple qui consiste à ajouter un délai d'attente.

Nous avons également ajouté un **`entrypoint`** pour le service **`api`** : 
- L'**`entrypoint`** est une commande qui est exécutée lorsque le conteneur est démarré. Ici, nous exécutons l'application Spring Boot en mode `test`. Nous avons vu dans le tutoriel sur les profils Spring Boot que nous pouvons utiliser le profil **`test`** pour exécuter l'application en mode test.
- L'**`entrypoint`** remplace la commande **`CMD`** dans le **`Dockerfile`** de l'API. Il est souvent utilisé pour passer des arguments à l'application.

Nous avons utilisé le profile **`test`** pour exécuter l'application en mode test. Nous devons donc changer la configuration de l'API en mode test pour que l'application puisse communiquer avec la base de données.  
Veuillez mettre à jour le fichier **`application-test.properties`** dans le répertoire **`src/main/resources`** de l'API :

```properties
spring.datasource.url=jdbc:postgresql://db:5432/cae_db
```

L'API qui tournera dans le conteneur Docker pourra communiquer avec la base de données PostgreSQL via le nom du service **`db`**.

Maintenant que nous avons mis à jour le **`Dockerfile`** et le **`docker-compose.yml`**, nous pouvons créer et exécuter l'image Docker pour l'environnement de tests et de production.

Veuillez exécuter la commande suivante à la racine de votre projet GitLab :

```bash
docker compose up --build
```

L'image de l'API est trop volumineuse. En effet, elle fait 572.46 MB.  
Nous allons voir comment optimiser l'image Docker de l'API pour la production.

## Optimisation de l'image Docker de l'API

Nous pouvons tenter d'utiliser une version `alpine` pour java. Veuillez mettre à jour le fichier **`Dockerfile`** à la racine de votre projet **`/api`** avec le contenu suivant :

```Dockerfile {8}
FROM maven:3.9.9-amazoncorretto-21 AS build

WORKDIR /app

COPY pom.xml .
COPY src ./src

RUN mvn clean package -Dno-build-failure

FROM amazoncorretto:21-alpine

WORKDIR /app

COPY --from=build /app/target/*.jar app.jar

EXPOSE 3000

CMD ["java", "-jar", "app.jar"]
```

L'image de l'API fait maintenant 367,93 MB. C'est déjà mieux, mais nous pouvons encore l'optimiser.

Notons qu'ici, comme nous avons déjà appliqué un multi-stages build, nous n'avons pas besoin d'utiliser un fichier **`.dockerignore`** pour exclure les fichiers inutiles de l'image Docker. En effet, les fichiers inutiles ne sont pas copiés dans l'image finale.

Après quelques recherches sur internet pour trouver une image Java plus légère, nous avons trouvé l'image **`eclipse-temurin`** qui est une distribution d'OpenJDK. Nous allons donc utiliser cette image pour l'API.

Veuillez mettre à jour le fichier **`Dockerfile`** à la racine de votre projet **`/api`** avec le contenu suivant :

```Dockerfile {10}
FROM maven:3.9.9-amazoncorretto-21 AS build

WORKDIR /app

COPY pom.xml .
COPY src ./src

RUN mvn clean package -Dno-build-failure

FROM eclipse-temurin:21-jre-jammy

WORKDIR /app

COPY --from=build /app/target/*.jar app.jar

EXPOSE 3000

CMD ["java", "-jar", "app.jar"]
```

L'image de l'API fait maintenant 326,85 MB. Ca n'est pas parfait, mais c'est déjà mieux, et nous nous contenterons de cette taille. 

Si vous souhaitez optimiser davantage l'image, vous allez probablement devoir creuser un peu plus le sujet.

Bien, maintenant que nous avons optimisé l'image Docker de l'API, nous pouvons créer et exécuter l'image Docker pour l'environnement de production.

Veuillez exécuter la commande suivante à la racine de votre projet GitLab :

```bash
docker compose up --build
```

Néanmoins, même si dans le terminal vous voyez que l'API est démarrée, vous ne pourrez pas accéder à l'API via l'adresse **`http://localhost:3000`**. En effet, l'API est démarrée dans un conteneur Docker, et le frontend ne peut pas communiquer avec l'API. Nous allons voir comment configurer les conteneurs pour qu'ils puissent communiquer entre eux.

# <InternalPageTitle> Comment connecter tous les services dans une application multi-conteneurs ? </InternalPageTitle>

## Introduction

Dans ce tutoriel, nous allons voir comment configurer les conteneurs pour qu'ils puissent communiquer entre eux. Nous allons connecter les services dans une application multi-conteneurs.

Revenons d'abord quelques instants sur la compréhension de l'environnement de développement.

## Compréhension de l'environnement de développement

Dans l'environnement de développement, la seule application que nous avons dockerisée est la base de données PostgreSQL. L'API Spring Boot et le frontend sont exécutés en dehors de Docker. L'API Spring Boot est exécutée à l'aide d'IntelliJ ou de Maven, et le frontend est exécuté à l'aide de **Vite**.

Voici un schéma de l'environnement de développement :

<PlantUML src="/diagrams/local-dev-deployment.puml" alt="Environnement de développement"/>

Dans cet environnement :
- le frontend peut communiquer avec l'API Spring Boot via l'adresse **`http://localhost:3000`**. 
- L'API Spring Boot peut communiquer avec la base de données PostgreSQL via l'adresse **`jdbc:postgresql://localhost:5432/cae_db`**.
- C'est le frontend, via **Vite** qui s'occupe de faire office de serveur de proxy pour rediriger les requêtes vers l'API. En effet, le frontend est exécuté sur le port **`5173`** et l'API sur le port **`3000`**. Pour que le frontend puisse communiquer avec l'API, il faut rediriger les requêtes du frontend vers l'API. C'est ce que fait **Vite** et son proxy intégré au serveur de développement à l'aide de la configuration du fichier **`vite.config.ts`**.  
```ts
server: {
    proxy: {
      '/api': {
        target: 'http://localhost:3000',
        changeOrigin: true,
        rewrite: (path) => path.replace(/^\/api/, ''),
      },
    },
  },
```
- Pour chaque requête qui commence par **`/api`**, **Vite** redirige la requête vers **`http://localhost:3000`**. Par exemple, dans le frontend, si vous faites une requête vers **`/api/pizza`**, **Vite** redirigera la requête vers **`http://localhost:3000/pizzas`**. Vous trouverez cette requête dans le fichier **`/frontend/src/components/App/index.tsx`** du frontend.

## Compréhension de l'environnement de tests actuel

Dans l'environnement de tests (proche de l'environnement de production final), toutes les applications sont dockerisées. Le frontend, l'API Spring Boot et la base de données PostgreSQL sont exécutés dans des conteneurs Docker.

Voici un schéma de l'environnement de tests actuel :

<PlantUML src="/diagrams/local-test-deployment1.puml" alt="Environnement de production"/>

Dans cet environnement, le frontend ne peut pas encore communiquer avec l'API Spring Boot car l'API est exécutée dans un conteneur Docker. Le frontend est exécuté sur le port **`80`** de l'hôte, et l'API est exécutée sur le port **`3000`** du conteneur Docker. 

Comme c'est le serveur de fichiers statiques **`nginx`** qui sert l'application frontend, en production, nous n'avons plus l'application **`Vite`** qui s'occupe de rediriger les requêtes du frontend vers l'API. Il faut donc configurer les conteneurs pour qu'ils puissent communiquer entre eux.

Pour que le frontend puisse communiquer avec l'API, on peut soit :
- Option 1 : faire en sorte que le frontend exécute directement les requêtes vers l'URL de l'API dans le conteneur Docker, c'est à dire **`http://frontend:3000`**. 
- Option 2 : soit utiliser un serveur de proxy pour rediriger les requêtes du frontend vers l'API. 
- Option 3 : soit utiliser un reverse proxy pour rediriger tant les requêtes du frontend que celles de l'API.


## Option 1 : Changer les URLs dans le frontend lors des appels à l'API dans le conteneur Docker

Nous pourrions faire en sorte que le frontend exécute directement les requêtes vers l'URL de l'API dans le conteneur Docker. Pour cela, il suffit de changer les URLs dans le frontend lors des appels à l'API.

Une première difficulté pour cette cette option est que nous devons changer les URLs dans le frontend à chaque fois que nous passons de l'environnement de développement à l'environnement de tests ou de production. Nous pouvons automatiser ça en utilisant des variables d'environnement. Quand nous sommes dans l'environnement de développement, nous utilisons l'URL **`http://localhost:3000`**. Quand nous sommes dans l'environnement de tests ou de production, nous utilisons l'URL **`http://frontend:3000`** pour faire les appels à l'API.  

Nous pouvons mettre imaginer cette option assez simple et mettre à jour les fichiers du frontend partout où il y a des appels à l'API : **`/frontend/src/components/App/index.tsx`** et **`/frontend/src/contexts/UserContext.tsx`**. :

Voici un exemple de mise à jour :

```tsx 
const baseUrl = import.meta.env.DEV ? '/api' : 'http://localhost:3000';
/...
const response = await fetch(`${baseUrl}/pizzas`);
```

Une autre difficulté pour cette option est que si l'API n'autorise pas les requêtes en provenance d'un autre domaine que celui de l'API, les requêtes du frontend vers l'API seront bloquées par le navigateur. En effet, le frontend est exécuté sur un domaine différent de celui de l'API. Pour que les requêtes du frontend vers l'API soient autorisées, il faut que l'API autorise les requêtes en provenance d'un autre domaine que celui de l'API. Cela peut être configuré dans l'API en ajoutant des en-têtes CORS pour autoriser les requêtes provenant du frontend.

Cette solution n'est pas très élégante, car en fonction d'où nous allons déployer l'application, nous devrons à chaque fois autoriser l'URL du frontend dans l'API. Ca n'est pas une solution optimale.

C'est pourquoi, nous allons voir une autre option plus élégante pour configurer les conteneurs pour qu'ils puissent communiquer entre eux.

## Option 2 : Utiliser un serveur de proxy pour rediriger les requêtes du frontend vers l'API

Pour cette option, il s'agit d'ajouter une nouvelle application **`nginx`** qui ferait office de proxy : son rôle serait, pour toutes les requêtes faites par le frontend sur le port **`80`** et contenant l'url **`/api`**, de les transférer vers  vers l'API sur le port **`3000`** du conteneur Docker.

Le côté gênant de cette option, c'est que pour éviter les problèmes de CORS, le serveur de proxy doit fonctionner sur le même port que le serveur de fichiers statiques du frontend. En effet, si le serveur de proxy fonctionne sur un autre port, les requêtes du frontend vers l'API seront bloquées par le navigateur.

Comme nous souhaitons que le frontend contienne un serveur de fichier dédié (**`nginx`** configuré juste pour le frontend), nous ne voulons pas envisager l'option de mettre à jour le serveur de fichier du frontend pour qu'il fasse office de proxy. Nous allons donc voir une autre option.

## Option 3 : Utiliser un reverse proxy pour rediriger tant les requêtes du frontend que celles de l'API

### Comment fonctionne un reverse proxy ?

Pour cette option, nous allons ajouter un reverse proxy, **`nginx`**, qui servira à la fois le frontend et l'API.  
Un reverse proxy est un serveur qui reçoit des requêtes de clients et les redirige vers un ou plusieurs serveurs en fonction de divers critères. Dans notre cas, le reverse proxy **`nginx`** recevra :
- les requêtes du frontend sur le port **`80`** et les redirigera vers le serveur de fichiers statiques du frontend.
- les requêtes de l'API sur le port **`3000`** et les redirigera vers l'API.

Comme nous ne pouvons pas avoir deux applications qui écoutent sur le même port, nous allons configurer le **`nginx`** du reverse proxy pour qu'il écoute sur le port **`80`** et redirige les requêtes vers le frontend ou l'API **en fonction du chemin de la requête** :
- Si le chemin de la requête commence par **`/api`**, le reverse proxy redirigera la requête vers l'API sur le port **`3000`** du conteneur Docker.
- Sinon, le reverse proxy redirigera la requête vers le frontend. 

Comme le **`nginx`** du serveur de fichiers statiques du frontend ne peut pas tourner sur le même port que le **`nginx`** du reverse proxy, nous allons changer le port du **`nginx`** du serveur de fichiers statiques du frontend pour qu'il écoute sur le port **`5172`** au lieu du port **`80`**.

Voici un schéma de l'environnement de tests avec un reverse proxy :

<PlantUML src="/diagrams/local-test-deployment2.puml" alt="Environnement de tests avec un reverse proxy"/>

Tout passe par le reverse proxy **`nginx`** qui redirige les requêtes vers le frontend ou l'API en fonction du chemin de la requête.

Voici les avantages de l'utilisation d'un reverse proxy :
- **Sécurité** : le reverse proxy peut servir de pare-feu pour protéger les applications contre les attaques.
- **Gestion des requêtes** : le reverse proxy peut gérer les requêtes entrantes et les rediriger vers les applications appropriées.
- **Équilibrage de charge** : le reverse proxy peut répartir la charge entre plusieurs serveurs pour améliorer les performances. On pourrait par exemple avoir plusieurs instances de l'API et le reverse proxy répartirait la charge entre ces instances.

Nous allons voir comment configurer les conteneurs pour qu'ils puissent communiquer entre eux en utilisant un reverse proxy.

## Configuration des conteneurs pour utiliser le reverse proxy

### Configuration du frontend

Dans un premier temps, nous devons configurer le frontend pour qu'il puisse communiquer avec le reverse proxy. Nous allons changer le port du serveur de fichiers statiques du frontend pour qu'il écoute sur le port **`5172`** au lieu du port **`80`**.

Veuillez ajouter un fichier **`nginx.conf`** à la racine du projet **`frontend`** avec le contenu suivant :

```nginx
events {
}

http {
    include /etc/nginx/mime.types;
    
    server {
        listen 5172;

        # Serve static files for the frontend
        location / {
            root /usr/share/nginx/html;
            try_files $uri $uri/ /index.html;
        }
    }
}
```

Il faut ensuite mettre à jour le **`Dockerfile`** du frontend. Veuillez mettre à jour le fichier **`Dockerfile`** à la racine de votre projet **`frontend`** avec le contenu suivant :

```Dockerfile {19,21,23} showLineNumbers
FROM node:20-alpine AS build

WORKDIR /app

COPY package*.json ./

RUN npm ci

COPY . .

RUN npm run build

FROM nginx:alpine AS prod

WORKDIR /usr/share/nginx/html

COPY --from=build /app/dist .

COPY nginx.conf /etc/nginx/nginx.conf

EXPOSE 5172

CMD ["nginx", "-g", "daemon off;"]
```

Nous devons aussi mettre à jour le **`docker-compose.yml`** pour que le frontend écoute sur le port **`5172`**. Veuillez mettre à jour le fichier **`docker-compose.yml`** à la racine de votre projet avec le contenu suivant :

```yaml {7-8}
services:
  frontend:
    container_name: frontend-prod
    image: frontend-prod
    build: 
      context: ./frontend
    ports:
      - 5172:5172
    depends_on:
      - api
```

### Configuration du reverse proxy

Nous allons ajouter un service **`reverse-proxy`**. Le reverse proxy écoutera sur le port **`80`** et redirigera les requêtes vers le frontend ou l'API en fonction du chemin de la requête.

Veuillez ajouter un fichier **`nginx.conf`** à la racine du projet GitLab avec le contenu suivant :

```nginx
events {
}

http {
    include /etc/nginx/mime.types;
    
    server {
        listen 80;

        # Proxy API requests
        location /api/ {
            proxy_pass http://api:3000/; # Forward to the API service
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }

        # Redirect all other requests to SPA
        location / {
            proxy_pass http://frontend:5172; # Forward to the SPA service
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }

    }
}
```

Nous avons deux blocs de configuration dans le fichier **`nginx.conf`** :
- **`location /api/`** : 
  - Redirige les requêtes qui commencent par **`/api`** vers l'API sur le port **`3000`** du conteneur Docker.
  - **`proxy_pass http://api:3000/;`** : Redirige les requêtes vers le service **`api`**.
- **`location /`** :
  - Redirige toutes les autres requêtes vers le frontend sur le port **`5172`** du conteneur Docker.
  - **`proxy_pass http://frontend:5172;`** : Redirige les requêtes vers le service **`frontend`**.

Il ne reste plus qu'à exposer le port du frontend sur l'hôte (**`5172:5172`**) et ajouter le service **`reverse-proxy`** au **`docker-compose.yml`**. Veuillez mettre à jour le fichier **`docker-compose.yml`** à la racine de votre projet avec le contenu suivant :

```yaml {8,32-41} showLineNumbers
services:
  frontend:
    container_name: frontend-prod
    image: frontend-prod
    build:
      context: ./frontend
    ports:
      - 5172:5172
    depends_on:
      - api

  api:
    container_name: api-prod
    image: api-prod
    build: ./api
    ports:
      - 3000:3000
    depends_on:
      - db
    entrypoint: ["java", "-jar", "app.jar", "--spring.profiles.active=test"]

  db:
    image: postgres:latest
    container_name: db-test
    environment:
      POSTGRES_DB: cae_db
      POSTGRES_USER: cae_user
      POSTGRES_PASSWORD: cae
    ports:
      - "5432:5432"

  reverse-proxy:
    container_name: reverse-proxy-prod
    image: nginx:alpine
    ports:
      - 80:80
    depends_on:
      - frontend
      - api
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
```

Nous avons ajouté un service **`reverse-proxy`**. Le reverse proxy écoutera sur le port **`80`** et redirigera les requêtes vers le frontend ou l'API en fonction du chemin de la requête.

Nous avons ajouté un volume pour monter le fichier **`nginx.conf`** dans le conteneur **`reverse-proxy`**. Cela permet de mettre à jour la configuration du reverse proxy sans avoir à reconstruire l'image Docker.

Maintenant que nous avons configuré les conteneurs pour qu'ils puissent communiquer entre eux en utilisant un reverse proxy, nous pouvons créer et exécuter les images Docker pour l'environnement de tests.

Veuillez exécuter la commande suivante à la racine de votre projet GitLab :

```bash
docker compose up --build
```

L'application est maintenant dockerisée et quasi prête pour les tests. Vous pouvez ouvrir un navigateur et accéder à l'adresse **`http://localhost`** pour voir l'application frontend en tests (très proche de l'environnement de production). Vous devriez voir l'application frontend servie par le reverse proxy **`nginx`**, et tout devrait être fonctionnel 🚀 !. 

Vous devriez aussi pouvoir accéder à l'API via l'adresse **`http://localhost/api`**.

Plus tard, nous ajouterons les tests e2e pour vérifier que tout fonctionne correctement.

# <InternalPageTitle> Comment réaliser les tests e2e dans l'environnement de production local ? </InternalPageTitle>

## Introduction

Dans ce tutoriel, nous allons voir comment réaliser les tests e2e dans l'environnement  de tests . Nous allons utiliser **Playwright** et tout ce qui a été mis en place précédemment pour réaliser les tests e2e.

### Création d'une image Docker pour les tests e2e

Pour réaliser les tests e2e dans l'environnement de tests , nous allons créer une image Docker pour les tests e2e. Cette image Docker contiendra les tests e2e et les dépendances nécessaires pour les exécuter.

Veuillez ajouter un fichier **`Dockerfile`** dans le répertoire **`e2e`** (répertoire contenant vos tests e2e) avec le contenu suivant :

```Dockerfile
FROM mcr.microsoft.com/playwright:v1.50.1-jammy
WORKDIR /app
COPY package*.json ./
COPY . .
RUN npm ci
CMD ["npx", "playwright", "test"]
```

Nous avons déjà vu comment créer une image Docker pour les tests e2e dans le tutoriel sur les tests e2e. Nous utilisons l'image **`mcr.microsoft.com/playwright:v1.50.1-jammy`** qui contient **Playwright** et toutes les dépendances nécessaires pour exécuter les tests e2e.

### Exécution des tests e2e dans l'environnement de tests

Pour exécuter les tests e2e dans l'environnement de tests, nous allons ajouter un service **`e2e`** au **`docker-compose.yml`**. Ce service exécutera les tests e2e dans l'environnement de tests.

Veuillez mettre à jour le fichier **`docker-compose.yml`** à la racine de votre projet avec le contenu suivant :

```yaml {43-52} showLineNumbers
services:
  frontend:
    container_name: frontend-prod
    image: frontend-prod
    build:
      context: ./frontend
    ports:
      - 5172:5172
    depends_on:
      - api

  api:
    container_name: api-prod
    image: api-prod
    build: ./api
    ports:
      - 3000:3000
    depends_on:
      - db
    entrypoint: ["java", "-jar", "app.jar", "--spring.profiles.active=test"]

  db:
    image: postgres:latest
    container_name: db-test
    environment:
      POSTGRES_DB: cae_db
      POSTGRES_USER: cae_user
      POSTGRES_PASSWORD: cae
    ports:
      - "5432:5432"

  reverse-proxy:
    container_name: reverse-proxy-prod
    image: nginx:alpine
    ports:
      - 80:80
    depends_on:
      - frontend
      - api
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf

  e2e:
    container_name: e2e-prod
    image: e2e-prod
    build: ./e2e
    environment:
      NODE_ENV: production
    depends_on:
      - api
      - frontend
    entrypoint: ["sh", "-c", "sleep 20 && npx playwright test"]
```

Nous avons ajouté un service **`e2e`** pour les tests e2e. Ce service exécutera les tests e2e dans l'environnement de tests. Nous avons ajouté une dépendance au service **`api`** et au service **`frontend`** car les tests e2e dépendent de ces services.

De plus, nous avons ajouté une instruction **`sleep 20`** avant d'exécuter les tests e2e. Cela permet d'attendre que les services **`api`** et **`frontend`** soient prêts avant d'exécuter les tests e2e.

Finalement, nous avons ajouté une variable d'environnement **`NODE_ENV: production`** pour indiquer que les tests e2e sont exécutés dans un environnement conforme à la production. Cette variable d'environnement sera utilisée pour déterminer l'URL à utiliser dans les tests e2e.

Attention que les tests e2e doivent contacter le frontend via le reverse proxy. Il faut donc mettre à jour les URLs des tests e2e pour utiliser :
- l'URL du reverse proxy **`http://reverse-proxy:80`** (au lieu de l'URL du frontend **`http://localhost:5173`**) lorsqu'on est dans l'environnement de tests. Comme c'est le reverse proxy qui redirige les requêtes vers le frontend, les tests e2e doivent contacter le reverse proxy pour accéder au frontend. Et comme c'est le container qui exécute les tests e2e qui doit contacter le reverse proxy, il faut utiliser le nom du service **`reverse-proxy`** pour accéder au reverse proxy (et pas **`localhost`**).
- l'URL du frontend directement **`http://frontend:5173`** seulement lorsqu'on est dans l'environnement de développement local.

Pour mettre à jour les URLs des tests e2e pour utiliser l'URL du reverse proxy ou celle du frontend selon l'environnement nous allons changer la configuration des tests e2e pour qu'elle détecte dans quel environnement elle est exécutée. Nous allons utiliser une variable d'environnement pour déterminer l'URL à utiliser.

Veuillez mettre à jour le fichier **`e2e/playwright.config.ts`** avec le contenu suivant :

```ts {18-22} showLineNumbers
import { defineConfig, devices } from "@playwright/test";

export default defineConfig({
  testDir: "./tests",
  /* Run tests in files in parallel */
  fullyParallel: true,
  /* Fail the build on CI if you accidentally left test.only in the source code. */
  forbidOnly: !!process.env.CI,
  /* Retry on CI only */
  retries: process.env.CI ? 2 : 0,
  /* Opt out of parallel tests on CI. */
  workers: process.env.CI ? 1 : undefined,
  /* Reporter to use. See https://playwright.dev/docs/test-reporters */
  reporter: "html",
  /* Shared settings for all the projects below. See https://playwright.dev/docs/api/class-testoptions. */
  use: {
    /* Base URL to use in actions like `await page.goto('/')`. */
    baseURL:
      process.env.NODE_ENV === undefined ||
      process.env.NODE_ENV === "development"
        ? "http://localhost:5173"
        : "http://reverse-proxy:80",

    /* Collect trace when retrying the failed test. See https://playwright.dev/docs/trace-viewer */
    trace: "on-first-retry",
  },

  /* Configure projects for major browsers */
  projects: [
    {
      name: "chromium",
      use: { ...devices["Desktop Chrome"] },
    },
  ],
});
```

Nous avons ajouté une condition pour déterminer l'URL à utiliser en fonction de la variable d'environnement **`NODE_ENV`**. Si la variable d'environnement **`NODE_ENV`** n'est pas définie ou si elle est égale à **`development`**, nous utilisons l'URL du frontend **`http://localhost:5173`**. Sinon, nous utilisons l'URL du reverse proxy **`http://reverse-proxy:80`**.

Nous devons aussi mettre à jour les tests e2e pour utiliser l'URL définie dans la configuration des tests e2e. Veuillez mettre à jour les fichiers de tests e2e dans le répertoire **`e2e/tests`** pour utiliser l'URL définie dans la configuration des tests e2e. Pour l'instant nous n'avons qu'un seul fichier à mettre à jour, c'est le fichier **`e2e/tests/helper.spec.ts`** :

```ts {4,6} showLineNumbers
import { Page, expect } from "@playwright/test";

const goFromHomePageToRegisterPage = async (page: Page) => {
  await page.goto("/");
  await page.getByText("créer un utilisateur").click();
  await expect(page).toHaveURL("/register");
};

const registerWith = async (page: Page, username: string, password: string) => {
  await page.getByRole("textbox", { name: "username" }).fill(username);
  await page.getByRole("textbox", { name: "password" }).fill(password);
  await page.getByRole("button", { name: "Créer le compte" }).click();
};

export { registerWith, goFromHomePageToRegisterPage };
```

Nous avons supprimé l'URL **`http://localhost:5173`** et nous avons remplacé par **`/`** pour utiliser la **`baseURL`** définie dans la configuration des tests e2e.

Maintenant que nous avons configuré les tests e2e pour qu'ils puissent être exécutés dans l'environnement de tests, nous pouvons créer et exécuter les images Docker pour l'environnement de tests.  
Pour cela, veuillez exécuter la commande suivante à la racine de votre projet GitLab :

```bash
docker compose up --build
```

Les tests e2e sont exécutés dans l'environnement de tests. Vous devriez voir les tests e2e s'exécuter et vérifier que tout fonctionne correctement. Si les tests échouent, vous devriez voir les erreurs dans la sortie de la commande.

## De quoi est constitué mon image ?

Quand on regarde avec Docker Desktop la taille de l'image pour le service **`e2e`**, on voit qu'elle est de 2,32 GB. C'est une taille assez conséquente pour des tests e2e.

En cliquant sur l'onglet **`Images`** de Docker Desktop, puis sur l'image **`e2e-prod`**, on peut voir les différentes couches de l'image Docker dans **`Layers`**. On peut voir des choses très intéressantes, comme par exemple :
- La couche 14 contient les dépendances de **`Playwright`** (dépendances système et pour les browsers). Pour voir la commande associée, on peut cliquer sur l'onglet **`Command`**. C'est la plus grosse couche de l'image, elle fait 1,91 GB ! 
On ne peut pas optimiser cette couche, car elle contient les dépendances nécessaires pour exécuter les tests e2e avec **`Playwright`**, et aussi, parce qu'elle fait partie de l'image de base **`mcr.microsoft.com/playwright:v1.50.1-jammy`**.
- La couche 18 contient l'installation des dépendances de notre projet de tests e2e (**`npm ci`**). Elle est peu volumineuse, elle fait 27,12 MB. 

# <InternalPageTitle> Comment ignorer les fichiers qui ne peuvent pas se retrouver dans l'image ? </InternalPageTitle>

Nous avons déjà vu comment optimiser les images Docker en utilisant un fichier **`.dockerignore`** pour exclure les fichiers inutiles. Nous allons revoir cela ici pour les tests e2e.


Lorsqu'on souhaite créer une image Docker, il est important de ne pas inclure les fichiers qui pourraient causer des soucis, comme révéler des secrets, ou rendre l'image trop volumineuse. Pour rappel, on peut utiliser un fichier **`.dockerignore`** pour exclure les fichiers et répertoires que l'on ne souhaite pas inclure dans l'image Docker.

Attention, il s'agit ici d'exclure les fichiers qui se trouvent sur l'hôte. Si vous souhaitez exclure des fichiers qui se trouvent dans l'image, il faudra le faire dans le **`Dockerfile`**.

Par exemple, si vous voulez vous assurer de ne pas utiliser les **`node_modules`** de l'hôte (votre machine) mais de toujours les installer dans le conteneur, vous pouvez ajouter un fichier **`.dockerignore`** à la racine du projet **`e2e`** avec le contenu suivant :

```git
node_modules
```

De la même manière, il est important de penser d'ajouter dans le fichier **`.dockerignore`** tous les fichiers et répertoires que vous ne souhaitez pas inclure dans l'image Docker, comme :
- l'éventuel **`.git`**
- l'éventuel **`.env`**
- l'inutile **`Dockerfile`** pour exécuter les tests e2e...
- le **`Readme`**, les fichiers de documentation...

Voila tout ce que nous pourrions exclure de l'image Docker pour les tests e2e :

```git
node_modules
dist
.git
.gitignore
Dockerfile
docker-compose.yml
README.md
.DS_Store
```

# <InternalPageTitle> Comment exécuter docker compose dans notre pipeline ? </InternalPageTitle>

## Introduction

Nous souhaitons maintenant exécuter notre application, avec tous ses services, dans notre pipeline GitLab. 

L'idée est de se simplifier au maximum la vie et de ne pas avoir à changer nos conteneurs pour passer dans l'environnement de tests. Nous allons donc utiliser **Docker Compose** pour exécuter notre application dans notre pipeline.

## Configuration de notre pipeline

Pour ce tutoriel, vous devez penser à créer une nouvelle branche dans votre projet GitLab. Vous pouvez par exemple créer une branche **`feature/dockerized`**.

Pour exécuter notre application avec Docker Compose dans notre pipeline, nous allons ajouter un stage **`e2e`**. Ce stage exécutera **Docker Compose** pour démarrer tous les services de notre application.

Veuillez mettre à jour le fichier **`.gitlab-ci.yml`** à la racine de votre projet avec le contenu suivant :

```yaml {3,43-62} showLineNumbers
stages:
  - test
  - e2e
variables:
  MAVEN_OPTS: "-Dmaven.repo.local=$CI_PROJECT_DIR/.m2/repository"

api test:
  stage: test
  image: maven:3.9.9-amazoncorretto-21
  cache:
    key:
      files:
        - api/pom.xml
    paths:
      - $CI_PROJECT_DIR/.m2/repository
  script:
    - cd api
    - mvn clean test
  artifacts:
    paths:
      - api/target/reports/
      - api/target/site/
      - api/target/surefire-reports/

frontend test:
  stage: test
  image: node:20-alpine
  cache:
    key:
      files:
        - frontend/package-lock.json
    paths:
      - frontend/node_modules
  script:
    - cd frontend
    - npm ci
    - npm run lint
    - npm run coverage
  artifacts:
    paths:
      - frontend/coverage/

e2e tests:
  stage: e2e
  image: docker:latest
  services:
    - docker:20-dind
  before_script:
    - docker-compose up --build -d
  script:
    - EXIT_CODE=$(docker wait e2e-prod)
    - docker-compose logs e2e
    - docker cp e2e-prod:/app/playwright-report ./e2e/playwright-report
    - docker cp e2e-prod:/app/test-results ./e2e/test-results
    - if [ "$EXIT_CODE" -ne 0 ]; then echo "E2E tests failed"; exit 1; fi
    - docker-compose down
  after_script:
    - docker-compose down
  artifacts:
    paths:
      - e2e/playwright-report/
      - e2e/test-results/
```

Voici les explications sur le stage **`e2e`** :
- Nous utilisons l'image **`docker:latest`** pour exécuter **Docker Compose** dans notre pipeline.
- Nous utilisons le service **`docker:20-dind`** pour exécuter Docker dans Docker (DinD).
- Nous utilisons la commande **`docker-compose up --build -d`** pour démarrer tous les services de notre application en arrière-plan.
- Nous utilisons la commande **`docker wait e2e-prod`** pour attendre que les tests e2e se terminent.
- Nous utilisons la commande **`docker cp`** pour copier les rapports des tests e2e et les résultats des tests e2e dans le répertoire **`e2e`**.
- **`EXIT_CODE`** contient le code de sortie des tests e2e. Si les tests échouent :
  - Le code de sortie est différent de 0.
  - Nous affichons un message d'erreur.
  - Nous sortons du pipeline avec un code de sortie différent de 0 : **`exit 1`** ; cela mettra le pipeline en échec.
- Nous utilisons la commande **`docker-compose down`** pour arrêter tous les services de notre application.

Maintenant que nous avons configuré notre pipeline pour exécuter notre application avec Docker Compose, nous pouvons exécuter notre pipeline GitLab. Il suffit de pousser votre branche (**`feature/dockerized`** par exemple) sur votre projet GitLab.

Nous devrions voir que tout fonctionne correctement et que les tests e2e s'exécutent dans notre pipeline GitLab. 

Mais comment réagit notre pipeline si les tests e2e échouent ? Nous allons voir cela dans la prochaine section.

## Que se passe-t-il si les tests e2e échouent ?

Veuillez mettre à jour votre fichier **`/e2e/tests/helper.spec.ts`** pour que les tests échouent. Par exemple, vous pouvez simplement tenter de naviguer vers une page qui n'existe pas ("**`/d`**") :

```ts {3}
const goFromHomePageToRegisterPage = async (page: Page) => {
  await page.goto("/d");
  await page.getByText("créer un utilisateur").click();
  await expect(page).toHaveURL("/register");
};
```

Poussez vos modifications sur votre branche **`feature/dockerized`**. Après plus de 5 minutes, vous devriez voir que les tests e2e continuent indéfiniment dans votre pipeline.

Par défaut, **Playwright** applique un timeout de 30 secondes pour les tests e2e. Si un test prend plus de 30 secondes, il est considéré comme échoué.  
Si vous souhaitez en savoir plus sur les timeouts dans **Playwright**, vous pouvez consulter la documentation officielle : https://playwright.dev/docs/test-timeouts

En fait, par défaut, playwright lance un serveur web pour afficher les résultats des tests. Si le test échoue, le serveur web ne s'arrête pas et le pipeline ne se termine pas. Pour résoudre ce problème, une des solutions est d'empêcher le serveur web de Playwright d'afficher les résultats des tests.

Veuillez mettre à jour le fichier **`e2e/playwright.config.ts`** avec le contenu suivant :

```ts {14-16} showLineNumbers
import { defineConfig, devices } from "@playwright/test";

export default defineConfig({
  testDir: "./tests",
  /* Run tests in files in parallel */
  fullyParallel: true,
  /* Fail the build on CI if you accidentally left test.only in the source code. */
  forbidOnly: !!process.env.CI,
  /* Retry on CI only */
  retries: process.env.CI ? 2 : 0,
  /* Opt out of parallel tests on CI. */
  workers: process.env.CI ? 1 : undefined,
  /* Reporter to use. See https://playwright.dev/docs/test-reporters */
  reporter: [
    ['html', { open: 'never' }],
],
  /* Shared settings for all the projects below. See https://playwright.dev/docs/api/class-testoptions. */
  use: {
    /* Base URL to use in actions like `await page.goto('/')`. */
    baseURL:
      process.env.NODE_ENV === undefined ||
      process.env.NODE_ENV === "development"
        ? "http://localhost:5173"
        : "http://reverse-proxy:80",

    /* Collect trace when retrying the failed test. See https://playwright.dev/docs/trace-viewer */
    trace: "on-first-retry",
  },

  /* Configure projects for major browsers */
  projects: [
    {
      name: "chromium",
      use: { ...devices["Desktop Chrome"] },
    },
  ],
});
```

Nous avons ajouté une option **`open: 'never'`** à la configuration du reporter **`html`**. Les résultats des tests seront enregistrés dans un fichier HTML, mais le navigateur ne sera pas ouvert pour les afficher.

Maintenant que nous avons empêché le serveur web de Playwright d'afficher les résultats des tests, nous pouvons exécuter à nouveau notre pipeline GitLab. Après environ 5 minutes de patience, vous devriez voir que les tests échouent et que le pipeline se termine en échec 🚀.

Veuillez maintenant remettre le fichier **`/e2e/tests/helper.spec.ts`** comme il était avant pour que les tests passent à nouveau.

# <InternalPageTitle> Comment gérer des règles pour notre pipelines ? </InternalPageTitle>

## Introduction

Dans notre tutoriel en cours sur la conteneurisation, nous avons vu comment exécuter notre application avec Docker Compose dans notre pipeline GitLab. Nous avons ajouté un stage **`e2e`** pour exécuter les tests e2e de notre application.

Néanmoins, voici quelques faiblesses de notre pipeline actuel :
- On n'a pas de stage pour construire les images Docker de notre application avant de faire les tests e2e.
- On ne déploie pas notre application sur le cloud.
- On n'exécute pas les tests e2e sur l'application déployée.
- Les tests e2e sont longs à s'exécuter et on doit actuellement le faire à chaque push sur notre branche.

Dans ce tutoriel, nous allons pas encore nous occuper du déploiement. Nous allons plutôt voir comment mieux organiser notre pipeline GitLab. Nous allons ajouter un stage **`build`** pour construire les images Docker de notre application avant de faire les tests e2e. 

## Configuration de notre pipeline avec un stage **`build`**

Nous souhaitons exécuter ces 3 stages en séquence dans notre pipeline :
1. **`test`** : Exécuter les tests unitaires et les tests statiques de notre application.
2. **`build`** : Construire les images Docker de notre application.
3. **`e2e`** : Exécuter les tests e2e de notre application seulement lors d'un événement spécifique. 

Un événement spécifique pourrait être :  
- Une merge request sur la branche **`main`**.
- Un push sur une branche spécifique .
- Un push contenant un mot-clé dans le message du commit.
- ...

Pour ce tutoriel, nous allons choisir de déclencher les tests e2e seulement lors d'une Merge Request sur la branche **`main`**.


Veuillez mettre à jour le fichier **`.gitlab-ci.yml`** à la racine de votre projet avec le contenu suivant :

```yaml {1-4,45-51,58-59} showLineNumbers
stages:
  - test
  - build
  - e2e

variables:
  MAVEN_OPTS: "-Dmaven.repo.local=$CI_PROJECT_DIR/.m2/repository"

api test:
  stage: test
  image: maven:3.9.9-amazoncorretto-21
  cache:
    key:
      files:
        - api/pom.xml
    paths:
      - $CI_PROJECT_DIR/.m2/repository
  script:
    - cd api
    - mvn clean test
  artifacts:
    paths:
      - api/target/reports/
      - api/target/site/
      - api/target/surefire-reports/

frontend test:
  stage: test
  image: node:20-alpine
  cache:
    key:
      files:
        - frontend/package-lock.json
    paths:
      - frontend/node_modules
  script:
    - cd frontend
    - npm ci
    - npm run lint
    - npm run coverage
  artifacts:
    paths:
      - frontend/coverage/

build:
  stage: build
  image: docker:latest
  services:
    - docker:20-dind
  script:
    - docker-compose build

e2e tests:
  stage: e2e
  image: docker:latest
  services:
    - docker:20-dind
  rules:
    - if: $CI_PIPELINE_SOURCE == "merge_request_event" && $CI_MERGE_REQUEST_TARGET_BRANCH_NAME == $CI_DEFAULT_BRANCH
  before_script:
    - docker-compose up -d
  script:
    - EXIT_CODE=$(docker wait e2e-prod)
    - docker-compose logs e2e
    - docker cp e2e-prod:/app/playwright-report ./e2e/playwright-report
    - docker cp e2e-prod:/app/test-results ./e2e/test-results
    - if [ "$EXIT_CODE" -ne 0 ]; then echo "E2E tests failed"; exit 1; fi
    - docker-compose down
  after_script:
    - docker-compose down
  artifacts:
    paths:
      - e2e/playwright-report/
      - e2e/test-results/
```

Voici les explications sur le stage **`build`** :
- Nous utilisons l'image **`docker:latest`** pour exécuter **Docker Compose** dans notre pipeline.
- Nous utilisons le service **`docker:20-dind`** pour exécuter Docker dans Docker (DinD).
- Nous utilisons la commande **`docker-compose build`** pour construire les images Docker de notre application.

Voici les explications sur le stage **`e2e`** :
- Nous utilisons la règle **`rules`** pour exécuter les tests e2e seulement lors d'une Merge Request sur la branche **`main`**.
- Nous utilisons la variable **`$CI_PIPELINE_SOURCE`** pour vérifier si l'événement est une Merge Request.
- Nous utilisons la variable **`$CI_MERGE_REQUEST_TARGET_BRANCH_NAME`** pour vérifier si la branche cible de la Merge Request est la branche par défaut (généralement la branche **`main`**).
- Notons qu'à chaque push sur une branche qui contient une Merge Request sur la branche **`main`**, les tests e2e s'exécuteront. Ceci est pratique, car à chaque fois que vous poussez une branche en dans le cadre de la review de la Merge Request, vous pouvez être sûr que les tests e2e s'exécuteront sur la branche **`main`**.

Maintenant que nous avons ajouté un stage **`build`** pour construire les images Docker de notre application, nous pouvons exécuter notre pipeline GitLab. Il suffit de pousser notre branche (**`feature/dockerized`** par exemple) sur notre projet GitLab.

Nous devrions voir que tout fonctionne correctement et que les images Docker de notre application sont construites avec succès. Bien sûr, il n'y a que les stages **`test`** et **`build`** qui s'exécutent pour le moment. Les tests e2e ne s'exécutent que lors d'une Merge Request sur la branche **`main`**.

Veuillez maintenant créer une Merge Request de votre "feature branch" vers la branche **`main`** pour voir les tests e2e s'exécuter dans votre pipeline GitLab.

## Conclusion sur la conteneurisation

Nous avons mis en place l'environnement de tests qui s'exécute dans notre pipeline GitLab. Nous avons ajouté un stage **`build`** pour construire les images Docker de notre application avant de faire les tests e2e. Nous avons ajouté un stage **`e2e`** pour exécuter les tests e2e seulement lors d'une Merge Request sur la branche **`main`**.

Voici à quoi ressemble l'environnement de tests dans notre pipeline GitLab :

<PlantUML src="/diagrams/test-deployment.puml" alt="Environnement de tests"/>

Lorsque les tests e2e s'exécutent, **Playwright** simule un utilisateur qui interagit avec l'application. Cela permet de vérifier que l'application fonctionne correctement et que l'expérience utilisateur est bonne. C'est donc l'application Playwright, via ses browsers intégrés, qui va ouvrir le navigateur, cliquer sur les boutons, remplir les formulaires, etc. 
En fait, Playwright va ouvrir un navigateur en mode headless (sans interface graphique) pour exécuter les tests. Ce browser va naviguer vers **`http://reverse-proxy:80`** pour accéder à l'application. Le reverse proxy va rediriger les requêtes vers le frontend ou l'API en fonction du chemin de la requête.
Une fois la SPA récupérée par le browser de Playwright, les tests vont pouvoir s'exécuter, les appels à l'API vont pouvoir être passé par le reverse proxy, etc. 
Playwright, via ses browsers intégrés, va donc pouvoir tester l'application dans son ensemble, comme si un utilisateur réel utilisait l'application.

Dans la partie sur la conteneurisation, nous avons appris à exécuter tout notre environnement de tests :
- Soit localement avec Docker Compose et une seule commande **`docker compose up --build`** !
- Soit dans notre pipeline GitLab avec les stages **`test`**, **`build`** et **`e2e`** lors de simples pushs sur notre branche et de la création d'une Merge Request.

C'est une grande avancée pour nos projets 🚀 ! Nous avons maintenant un environnement de tests complet qui s'exécute automatiquement à chaque push sur notre branche. Nous pouvons être sûr que notre application fonctionne correctement et que les tests e2e valident l'application avant d'intégrer les changements dans la branche **`main`**.

Dans la suite, nous allons voir comment déployer notre application sur le cloud, dans un véritable environnement de production. Et nous allons voir comment exécuter les tests e2e sur cet environnement de production.

Si nécessaire, vous pouvez trouver le code associé à la conteneurisation ici : [containerization](https://github.com/e-vinci/cae-theory-demos/tree/main/containerization).

